{
"nbformat": 4,
"nbformat_minor": 0,
"metadata": {
"kernelspec": {
"name": "python3",
"display_name": "Python 3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.6.5"
},
"colab": {
"name": "TextRank-doc-summary.ipynb",
"provenance": [],
"include_colab_link": true
}
},
"cells": [
{
"cell_type": "markdown",
"metadata": {
"id": "view-in-github",
"colab_type": "text"
},
"source": [
"<a href=\"https://colab.research.google.com/github/meteor79/TPS/blob/master/TextRank_doc_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
]
},
{
"cell_type": "code",
"metadata": {
"id": "eVAhUTA96uek",
"colab_type": "code",
"outputId": "699b33d1-45f5-45c3-c075-df9e3725457f",
"colab": {
"base_uri": "https://localhost:8080/",
"height": 1000
}
},
"source": [
"!pip install newspaper3k # url 크롤링 패키지\n",
"!pip install jpype1\n",
"!pip install konlpy # 한글 형태소 분석기\n",
"!pip install scikit-learn # TF-IDF를 위한 머신러닝 패키지\n",
"!pip install html2text"
],
"execution_count": 0,
"outputs": [
{
"output_type": "stream",
"text": [
"Collecting newspaper3k\n",
"\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
"\r\u001b[K     |█▌                              | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 2.7MB/s \n",
"\u001b[?25hCollecting cssselect>=0.9.2\n",
"  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
"Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
"Collecting feedfinder2>=0.0.4\n",
"  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
"Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (6.2.2)\n",
"Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
"Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.21.0)\n",
"Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
"Collecting feedparser>=5.2.1\n",
"\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
"\u001b[K     |████████████████████████████████| 194kB 8.7MB/s \n",
"\u001b[?25hCollecting jieba3k>=0.35.1\n",
"\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
"\u001b[K     |████████████████████████████████| 7.4MB 5.3MB/s \n",
"\u001b[?25hCollecting tldextract>=2.0.1\n",
"\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
"\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
"\u001b[?25hCollecting tinysegmenter==0.3\n",
"  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
"Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
"Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.6.1)\n",
"Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.12.0)\n",
"Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2.8)\n",
"Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
"Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2019.11.28)\n",
"Collecting requests-file>=1.4\n",
"  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
"Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (45.1.0)\n",
"Building wheels for collected packages: feedfinder2, feedparser, jieba3k, tinysegmenter\n",
"  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
"  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3357 sha256=9c6e2920693a390074dda3c3eafd570ceec27f618dd3bf6c886082deb3e116c0\n",
"  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
"  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
"  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=c251356da7a7dbc885bf0d33c5e868f5dade33908608c04643c57cc3f36e9f31\n",
"  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
"  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
"  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=b797308532e553bac8ae0a644652179b227b3b905467338e27bfdc17f296e032\n",
"  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
"  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
"  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13539 sha256=844e39d7d1d06be5d3171c67ca897023de7cab14e8188b10078562fcf3d4f7a8\n",
"  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
"Successfully built feedfinder2 feedparser jieba3k tinysegmenter\n",
"Installing collected packages: cssselect, feedfinder2, feedparser, jieba3k, requests-file, tldextract, tinysegmenter, newspaper3k\n",
"Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.4.3 tinysegmenter-0.3 tldextract-2.2.2\n",
"Collecting jpype1\n",
"\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/90/a94a55a58edfd67360fef85894bfb136a2c28b2cc7227d3a44dc508d5900/JPype1-0.7.1-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
"\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s \n",
"\u001b[?25hInstalling collected packages: jpype1\n",
"Successfully installed jpype1-0.7.1\n",
"Collecting konlpy\n",
"\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
"\u001b[K     |████████████████████████████████| 19.4MB 160kB/s \n",
"\u001b[?25hRequirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.1)\n",
"Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
"Collecting colorama\n",
"  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
"Collecting tweepy>=3.7.0\n",
"  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
"Collecting beautifulsoup4==4.6.0\n",
"\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
"\u001b[K     |████████████████████████████████| 92kB 7.3MB/s \n",
"\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
"Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
"Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
"Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
"Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
"Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
"Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
"Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
"Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
"Installing collected packages: colorama, tweepy, beautifulsoup4, konlpy\n",
"  Found existing installation: tweepy 3.6.0\n",
"    Uninstalling tweepy-3.6.0:\n",
"      Successfully uninstalled tweepy-3.6.0\n",
"  Found existing installation: beautifulsoup4 4.6.3\n",
"    Uninstalling beautifulsoup4-4.6.3:\n",
"      Successfully uninstalled beautifulsoup4-4.6.3\n",
"Successfully installed beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n",
"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\n",
"Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
"Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
"Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.5)\n",
"Collecting html2text\n",
"  Downloading https://files.pythonhosted.org/packages/ae/88/14655f727f66b3e3199f4467bafcc88283e6c31b562686bf606264e09181/html2text-2020.1.16-py3-none-any.whl\n",
"Installing collected packages: html2text\n",
"Successfully installed html2text-2020.1.16\n"
],
"name": "stdout"
}
]
},
{
"cell_type": "code",
"metadata": {
"id": "uOV2mmO76f5q",
"colab_type": "code",
"colab": {}
},
"source": [
"# -*- coding: utf-8 -*-\n",
"\n",
"from konlpy.tag import Kkma\n",
"from konlpy.tag import Okt\n",
"from sklearn.feature_extraction.text import TfidfVectorizer\n",
"from sklearn.feature_extraction.text import CountVectorizer\n",
"from sklearn.preprocessing import normalize\n",
"import numpy as np\n",
"import requests\n",
"import html2text\n",
"\n",
"\n",
"def getHtmlText(url):\n",
"    try:\n",
"        headers = {'User-agent': 'Mozilla/5.0'}\n",
"        page = requests.get(url, headers=headers)        \n",
"        html_code = page.content        \n",
"        h = html2text.HTML2Text()                 \n",
"        h.ignore_links = True\n",
"        h.ignore_images = True\n",
"        h.single_line_break = True                     \n",
"        text = h.handle(html_code.decode(\"utf-8\"))\n",
"        return text\n",
"    except Exception as e:\n",
"        print(e)\n",
"        return null\n",
"\n",
"# 문장 추출\n",
"class SentenceTokenizer(object):\n",
"    def __init__(self):\n",
"        self.kkma = Kkma()\n",
"        self.Okt = Okt()\n",
"           \n",
"    def url2sentences(self, url):\n",
"        htmltext = getHtmlText(url)\n",
"        sentences = self.kkma.sentences(htmltext)\n",
"        # for idx in range(0, len(sentences)):\n",
"        #     if len(sentences[idx]) <= 10:\n",
"        #         sentences[idx-1] += (' ' + sentences[idx])\n",
"        #         sentences[idx] = ''        \n",
"        return sentences\n",
"  \n",
"    def text2sentences(self, text):\n",
"        sentences = self.kkma.sentences(text)      \n",
"        for idx in range(0, len(sentences)):\n",
"            if len(sentences[idx]) <= 10:\n",
"                sentences[idx-1] += (' ' + sentences[idx])\n",
"                sentences[idx] = ''\n",
"        return sentences\n",
"\n",
"    def get_nouns(self, sentences):\n",
"        '''KoNLPy로 형태소 분석하기''' # --- ( ※ 3) \n",
"        nouns = []\n",
"        for sentence in sentences:\n",
"            word_s = self.Okt.pos(sentence, norm=True, stem=True)\n",
"            for n, h in word_s:\n",
"                if not (h in ['Noun']): continue\n",
"                if h == 'Punctuation' and h2 == 'Number': continue\n",
"                nouns.append(n)\n",
"        return nouns\n",
"\n",
"\n",
"# TF-IDF 모델 생성 및 그래프 생성\n",
"class GraphMatrix(object):\n",
"    def __init__(self):\n",
"        self.tfidf = TfidfVectorizer()\n",
"        self.cnt_vec = CountVectorizer()\n",
"        self.graph_sentence = []\n",
"    def build_sent_graph(self, sentence):\n",
"        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
"        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
"        return self.graph_sentence\n",
"    def build_words_graph(self, sentence):\n",
"        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
"        vocab = self.cnt_vec.vocabulary_\n",
"        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
"\n",
"\n",
"\n",
"#TextRank 알고리즘 적용\n",
"class Rank(object):\n",
"    def get_ranks(self, graph, d=0.85): \n",
"        A = graph\n",
"        matrix_size = A.shape[0]\n",
"        for id in range(matrix_size):\n",
"            A[id, id] = 0 \n",
"            link_sum = np.sum(A[:,id])\n",
"            if link_sum != 0:\n",
"                A[:, id] /= link_sum\n",
"            A[:, id] *= -d\n",
"            A[id, id] = 1\n",
"        B = (1-d) * np.ones((matrix_size, 1))\n",
"        ranks = np.linalg.solve(A, B) \n",
"        return {idx: r[0] for idx, r in enumerate(ranks)}\n",
"\n",
"\n",
"#TextRank Class 구현\n",
"class TextRank(object):\n",
"    def __init__(self, text):\n",
"        self.sent_tokenize = SentenceTokenizer()\n",
"        \n",
"        if text[:5] in ('http:', 'https'):\n",
"            self.sentences = self.sent_tokenize.url2sentences(text)\n",
"        else:\n",
"            self.sentences = self.sent_tokenize.text2sentences(text)\n",
"  \n",
"        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
"        \n",
"        print(self.nouns)\n",
"        # self.graph_matrix = GraphMatrix()\n",
"        # self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
"        # self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
"\n",
"        # self.rank = Rank()\n",
"        # self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
"        # self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
"\n",
"        # self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
"        # self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
"    \n",
"    def summarize(self, sent_num=3):\n",
"        summary = []\n",
"        index=[]\n",
"        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
"            index.append(idx)\n",
"        index.sort()\n",
"\n",
"        for idx in index:\n",
"            summary.append(self.sentences[idx])\n",
"        return summary\n",
"\n",
"    def keywords(self, word_num=10):\n",
"        rank = Rank()\n",
"        rank_idx = rank.get_ranks(self.words_graph)\n",
"        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
"\n",
"        keywords = []\n",
"        index=[]\n",
"        \n",
"        for idx in sorted_rank_idx[:word_num]:\n",
"            index.append(idx)\n",
"\n",
"        #index.sort()\n",
"        for idx in index:\n",
"            keywords.append(self.idx2word[idx])\n",
"\n",
"        return keywords\n"
],
"execution_count": 0,
"outputs": []
},
{
"cell_type": "code",
"metadata": {
"id": "Ht3G5b2k7-GG",
"colab_type": "code",
"colab": {}
},
"source": [
"def run_text_rank(url, summarize_num):\n",
"    textrank = TextRank(url)\n",
"    rows = textrank.summarize(summarize_num)\n",
"    print (rows)\n",
"    # for row in :  # 몇 줄로 요약할꺼야\n",
"    #     print(row)\n",
"    #     print('\\n')\n",
"    #     print('keywords :')\n",
"    #     print(textrank.keywords())"
],
"execution_count": 0,
"outputs": []
},
{
"cell_type": "code",
"metadata": {
"id": "U_NpjE1m6f5x",
"colab_type": "code",
"outputId": "105cb72d-5891-4af8-b632-5b4586b37353",
"colab": {
"base_uri": "https://localhost:8080/",
"height": 306
}
},
"source": [
"run_text_rank(\"http://www.diningcode.com/profile.php?rid=BpZCgY9DffCt\", 3)\n"
],
"execution_count": 0,
"outputs": [
{
"output_type": "error",
"ename": "TypeError",
"evalue": "ignored",
"traceback": [
"\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
"\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
"\u001b[0;32m<ipython-input-4-f921505db9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_text_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://www.diningcode.com/profile.php?rid=BpZCgY9DffCt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
"\u001b[0;32m<ipython-input-3-8577789d26c3>\u001b[0m in \u001b[0;36mrun_text_rank\u001b[0;34m(url, summarize_num)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_text_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtextrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextrank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# for row in :  # 몇 줄로 요약할꺼야\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
"\u001b[0;32m<ipython-input-2-e88763f3f100>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTextRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'http:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
"\u001b[0;32m<ipython-input-2-e88763f3f100>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSentenceTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkkma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKkma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOkt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         self.stopwords = [\"아\", \"휴\", \"아이구\", \"아이쿠\", \"아이고\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\"\n",
"\u001b[0;32m/usr/local/lib/python3.6/dist-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvmpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misJVMStarted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mjvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvmpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mkkmaJavaPackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJPackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kr.lucypark.kkma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
"\u001b[0;32m/usr/local/lib/python3.6/dist-packages/konlpy/jvm.py\u001b[0m in \u001b[0;36minit_jvm\u001b[0;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                 \u001b[0;34m'-Dfile.encoding=UTF8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                 \u001b[0;34m'-ea'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-Xmx{}m'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_heap_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                 convertStrings=True)\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please specify the JVM path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
"\u001b[0;31mTypeError\u001b[0m: startJVM() got an unexpected keyword argument 'convertStrings'"
]
}
]
},
{
"cell_type": "code",
"metadata": {
"id": "BJr2ezJ7MUlv",
"colab_type": "code",
"colab": {}
},
"source": [
""
],
"execution_count": 0,
"outputs": []
}
]
}
